{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_0</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>sensor_9</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_13</th>\n",
       "      <th>sensor_14</th>\n",
       "      <th>sensor_15</th>\n",
       "      <th>sensor_16</th>\n",
       "      <th>sensor_17</th>\n",
       "      <th>sensor_18</th>\n",
       "      <th>sensor_19</th>\n",
       "      <th>parcel_0</th>\n",
       "      <th>parcel_1</th>\n",
       "      <th>parcel_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sensor_0  sensor_1  sensor_2  sensor_3  sensor_4  sensor_5  sensor_6  \\\n",
       "0       1.0       2.0       1.0       7.0       0.0       1.0       1.0   \n",
       "1       5.0       1.0       3.0       5.0       2.0       2.0       1.0   \n",
       "2       3.0       1.0       4.0       3.0       4.0       0.0       1.0   \n",
       "3       2.0       2.0       4.0       3.0       5.0       0.0       3.0   \n",
       "4       4.0       3.0       3.0       2.0       5.0       1.0       3.0   \n",
       "\n",
       "   sensor_7  sensor_8  sensor_9  ...  sensor_13  sensor_14  sensor_15  \\\n",
       "0       4.0       0.0       3.0  ...        8.0        1.0        0.0   \n",
       "1       2.0       3.0       1.0  ...        4.0        5.0        5.0   \n",
       "2       6.0       0.0       2.0  ...        3.0        3.0        1.0   \n",
       "3       2.0       2.0       5.0  ...        4.0        1.0        1.0   \n",
       "4       1.0       1.0       2.0  ...        1.0        3.0        2.0   \n",
       "\n",
       "   sensor_16  sensor_17  sensor_18  sensor_19  parcel_0  parcel_1  parcel_2  \n",
       "0        2.0        1.0        9.0        2.0         0         1         0  \n",
       "1        2.0        2.0        2.0        7.0         0         0         0  \n",
       "2        0.0        3.0        1.0        0.0         1         1         0  \n",
       "3        4.0        1.0        3.0        2.0         0         0         0  \n",
       "4        2.0        1.0        1.0        0.0         1         1         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/irrigation_machine.csv\",index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2000 entries, 0 to 1999\n",
      "Data columns (total 23 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   sensor_0   2000 non-null   float64\n",
      " 1   sensor_1   2000 non-null   float64\n",
      " 2   sensor_2   2000 non-null   float64\n",
      " 3   sensor_3   2000 non-null   float64\n",
      " 4   sensor_4   2000 non-null   float64\n",
      " 5   sensor_5   2000 non-null   float64\n",
      " 6   sensor_6   2000 non-null   float64\n",
      " 7   sensor_7   2000 non-null   float64\n",
      " 8   sensor_8   2000 non-null   float64\n",
      " 9   sensor_9   2000 non-null   float64\n",
      " 10  sensor_10  2000 non-null   float64\n",
      " 11  sensor_11  2000 non-null   float64\n",
      " 12  sensor_12  2000 non-null   float64\n",
      " 13  sensor_13  2000 non-null   float64\n",
      " 14  sensor_14  2000 non-null   float64\n",
      " 15  sensor_15  2000 non-null   float64\n",
      " 16  sensor_16  2000 non-null   float64\n",
      " 17  sensor_17  2000 non-null   float64\n",
      " 18  sensor_18  2000 non-null   float64\n",
      " 19  sensor_19  2000 non-null   float64\n",
      " 20  parcel_0   2000 non-null   int64  \n",
      " 21  parcel_1   2000 non-null   int64  \n",
      " 22  parcel_2   2000 non-null   int64  \n",
      "dtypes: float64(20), int64(3)\n",
      "memory usage: 375.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:,-3:].values\n",
    "X = df.drop([\"parcel_0\",\"parcel_1\",\"parcel_2\"],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y,shuffle=True)\n",
    "# sc = StandardScaler()\n",
    "# sc.fit(X_train)\n",
    "# X_train_scaled = sc.transform(X_train)\n",
    "# X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_61 (Dense)            (None, 128)               2688      \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29635 (115.76 KB)\n",
      "Trainable params: 29635 (115.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128,input_shape=(20,),activation=\"relu\"))\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dense(3,activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"RMSprop\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "64/64 [==============================] - 1s 4ms/step - loss: 0.3783 - accuracy: 0.6008 - val_loss: 0.3070 - val_accuracy: 0.6594\n",
      "Epoch 2/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.5852 - val_loss: 0.3166 - val_accuracy: 0.6094\n",
      "Epoch 3/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.5680 - val_loss: 0.2225 - val_accuracy: 0.5281\n",
      "Epoch 4/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.5648 - val_loss: 0.2392 - val_accuracy: 0.5156\n",
      "Epoch 5/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.5562 - val_loss: 0.2357 - val_accuracy: 0.6562\n",
      "Epoch 6/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.5492 - val_loss: 0.2887 - val_accuracy: 0.5781\n",
      "Epoch 7/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.5477 - val_loss: 0.2745 - val_accuracy: 0.6156\n",
      "Epoch 8/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.5422 - val_loss: 0.2491 - val_accuracy: 0.6594\n",
      "Epoch 9/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1729 - accuracy: 0.5430 - val_loss: 0.2976 - val_accuracy: 0.4313\n",
      "Epoch 10/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1655 - accuracy: 0.5320 - val_loss: 0.2477 - val_accuracy: 0.5531\n",
      "Epoch 11/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.5234 - val_loss: 0.2603 - val_accuracy: 0.6187\n",
      "Epoch 12/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1506 - accuracy: 0.5344 - val_loss: 0.2825 - val_accuracy: 0.4906\n",
      "Epoch 13/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.5109 - val_loss: 0.2819 - val_accuracy: 0.5437\n",
      "Epoch 14/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1376 - accuracy: 0.5117 - val_loss: 0.3267 - val_accuracy: 0.4781\n",
      "Epoch 15/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.4945 - val_loss: 0.3413 - val_accuracy: 0.5125\n",
      "Epoch 16/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.5312 - val_loss: 0.2909 - val_accuracy: 0.4969\n",
      "Epoch 17/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.5180 - val_loss: 0.3162 - val_accuracy: 0.5188\n",
      "Epoch 18/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.5063 - val_loss: 0.3667 - val_accuracy: 0.4938\n",
      "Epoch 19/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.5180 - val_loss: 0.3697 - val_accuracy: 0.6625\n",
      "Epoch 20/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.5344 - val_loss: 0.3744 - val_accuracy: 0.5531\n",
      "Epoch 21/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.5023 - val_loss: 0.3568 - val_accuracy: 0.5688\n",
      "Epoch 22/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.5211 - val_loss: 0.4273 - val_accuracy: 0.5844\n",
      "Epoch 23/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0784 - accuracy: 0.5281 - val_loss: 0.4097 - val_accuracy: 0.5906\n",
      "Epoch 24/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.5148 - val_loss: 0.4584 - val_accuracy: 0.5500\n",
      "Epoch 25/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.5078 - val_loss: 0.4912 - val_accuracy: 0.4844\n",
      "Epoch 26/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.5367 - val_loss: 0.4785 - val_accuracy: 0.4719\n",
      "Epoch 27/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.5070 - val_loss: 0.5037 - val_accuracy: 0.5688\n",
      "Epoch 28/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.5547 - val_loss: 0.5396 - val_accuracy: 0.5688\n",
      "Epoch 29/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0516 - accuracy: 0.5336 - val_loss: 0.5293 - val_accuracy: 0.6313\n",
      "Epoch 30/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.5164 - val_loss: 0.6428 - val_accuracy: 0.5063\n",
      "Epoch 31/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.5555 - val_loss: 0.5450 - val_accuracy: 0.5031\n",
      "Epoch 32/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.5344 - val_loss: 0.5896 - val_accuracy: 0.6250\n",
      "Epoch 33/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.5437 - val_loss: 0.6056 - val_accuracy: 0.5906\n",
      "Epoch 34/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.5555 - val_loss: 0.6398 - val_accuracy: 0.6094\n",
      "Epoch 35/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.5219 - val_loss: 0.6887 - val_accuracy: 0.4969\n",
      "Epoch 36/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.5852 - val_loss: 0.7641 - val_accuracy: 0.4781\n",
      "Epoch 37/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.5562 - val_loss: 0.6390 - val_accuracy: 0.6250\n",
      "Epoch 38/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.5594 - val_loss: 0.7276 - val_accuracy: 0.5281\n",
      "Epoch 39/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.5320 - val_loss: 0.7924 - val_accuracy: 0.6125\n",
      "Epoch 40/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.5547 - val_loss: 0.7912 - val_accuracy: 0.6375\n",
      "Epoch 41/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.5883 - val_loss: 0.7959 - val_accuracy: 0.5656\n",
      "Epoch 42/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.5531 - val_loss: 0.8082 - val_accuracy: 0.4750\n",
      "Epoch 43/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.5594 - val_loss: 0.9107 - val_accuracy: 0.6906\n",
      "Epoch 44/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.6109 - val_loss: 0.9332 - val_accuracy: 0.4594\n",
      "Epoch 45/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.6086 - val_loss: 0.8274 - val_accuracy: 0.6187\n",
      "Epoch 46/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.6367 - val_loss: 0.9212 - val_accuracy: 0.6406\n",
      "Epoch 47/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.6180 - val_loss: 0.8457 - val_accuracy: 0.6187\n",
      "Epoch 48/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.5758 - val_loss: 0.9168 - val_accuracy: 0.6031\n",
      "Epoch 49/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 0.5758 - val_loss: 0.9661 - val_accuracy: 0.5688\n",
      "Epoch 50/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.5867 - val_loss: 0.9716 - val_accuracy: 0.5312\n",
      "Epoch 51/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.5547 - val_loss: 1.0485 - val_accuracy: 0.5906\n",
      "Epoch 52/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.6047 - val_loss: 0.9335 - val_accuracy: 0.7094\n",
      "Epoch 53/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.6281 - val_loss: 1.1374 - val_accuracy: 0.5625\n",
      "Epoch 54/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.6234 - val_loss: 0.9767 - val_accuracy: 0.6187\n",
      "Epoch 55/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.6078 - val_loss: 1.0268 - val_accuracy: 0.6250\n",
      "Epoch 56/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.6375 - val_loss: 1.1816 - val_accuracy: 0.6438\n",
      "Epoch 57/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.6359 - val_loss: 1.0841 - val_accuracy: 0.6656\n",
      "Epoch 58/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.6234 - val_loss: 1.1139 - val_accuracy: 0.6625\n",
      "Epoch 59/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.6328 - val_loss: 1.1378 - val_accuracy: 0.6687\n",
      "Epoch 60/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.6375 - val_loss: 1.0715 - val_accuracy: 0.6094\n",
      "Epoch 61/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.6117 - val_loss: 1.1278 - val_accuracy: 0.6469\n",
      "Epoch 62/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.5914 - val_loss: 1.1077 - val_accuracy: 0.6156\n",
      "Epoch 63/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.5750 - val_loss: 1.1845 - val_accuracy: 0.5906\n",
      "Epoch 64/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.6008 - val_loss: 1.1987 - val_accuracy: 0.5406\n",
      "Epoch 65/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.5992 - val_loss: 1.2183 - val_accuracy: 0.6281\n",
      "Epoch 66/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.5656 - val_loss: 1.2755 - val_accuracy: 0.5656\n",
      "Epoch 67/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.5742 - val_loss: 1.9377 - val_accuracy: 0.5344\n",
      "Epoch 68/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.5586 - val_loss: 1.1424 - val_accuracy: 0.5906\n",
      "Epoch 69/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.5311e-04 - accuracy: 0.5992 - val_loss: 1.1609 - val_accuracy: 0.6094\n",
      "Epoch 70/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.5766 - val_loss: 1.2109 - val_accuracy: 0.5781\n",
      "Epoch 71/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.5914 - val_loss: 1.2162 - val_accuracy: 0.6250\n",
      "Epoch 72/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.5570 - val_loss: 1.1909 - val_accuracy: 0.5344\n",
      "Epoch 73/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.5836 - val_loss: 1.2674 - val_accuracy: 0.5562\n",
      "Epoch 74/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.5797 - val_loss: 1.4035 - val_accuracy: 0.6062\n",
      "Epoch 75/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.5891 - val_loss: 1.2782 - val_accuracy: 0.5813\n",
      "Epoch 76/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.5883 - val_loss: 1.2413 - val_accuracy: 0.5469\n",
      "Epoch 77/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.5539 - val_loss: 1.2389 - val_accuracy: 0.5406\n",
      "Epoch 78/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.5953 - val_loss: 1.1819 - val_accuracy: 0.5750\n",
      "Epoch 79/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 9.5725e-04 - accuracy: 0.5945 - val_loss: 1.2743 - val_accuracy: 0.6562\n",
      "Epoch 80/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.5695 - val_loss: 1.4623 - val_accuracy: 0.5250\n",
      "Epoch 81/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.5578 - val_loss: 1.2479 - val_accuracy: 0.5750\n",
      "Epoch 82/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.5875 - val_loss: 1.3037 - val_accuracy: 0.5781\n",
      "Epoch 83/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.6055 - val_loss: 1.2884 - val_accuracy: 0.6219\n",
      "Epoch 84/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 0.6055 - val_loss: 1.2058 - val_accuracy: 0.6625\n",
      "Epoch 85/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.6133 - val_loss: 1.2760 - val_accuracy: 0.5875\n",
      "Epoch 86/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.5617 - val_loss: 1.3026 - val_accuracy: 0.5437\n",
      "Epoch 87/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.5648 - val_loss: 1.4245 - val_accuracy: 0.5781\n",
      "Epoch 88/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.5906 - val_loss: 1.4726 - val_accuracy: 0.5531\n",
      "Epoch 89/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.5953 - val_loss: 1.2995 - val_accuracy: 0.4938\n",
      "Epoch 90/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 0.5922 - val_loss: 1.3869 - val_accuracy: 0.6344\n",
      "Epoch 91/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.6039 - val_loss: 1.4788 - val_accuracy: 0.6781\n",
      "Epoch 92/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 0.6313 - val_loss: 1.4268 - val_accuracy: 0.6187\n",
      "Epoch 93/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.6461 - val_loss: 1.5194 - val_accuracy: 0.6656\n",
      "Epoch 94/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.6234 - val_loss: 1.5135 - val_accuracy: 0.5938\n",
      "Epoch 95/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.6078 - val_loss: 1.4963 - val_accuracy: 0.6187\n",
      "Epoch 96/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.6141 - val_loss: 1.5952 - val_accuracy: 0.5938\n",
      "Epoch 97/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.5961 - val_loss: 1.5135 - val_accuracy: 0.6062\n",
      "Epoch 98/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.6273 - val_loss: 1.4559 - val_accuracy: 0.6562\n",
      "Epoch 99/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 0.6289 - val_loss: 1.5362 - val_accuracy: 0.6344\n",
      "Epoch 100/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.6484 - val_loss: 1.3949 - val_accuracy: 0.6344\n",
      "Epoch 101/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.6125 - val_loss: 1.4502 - val_accuracy: 0.5969\n",
      "Epoch 102/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 0.6039 - val_loss: 1.4663 - val_accuracy: 0.5938\n",
      "Epoch 103/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.5828 - val_loss: 1.4651 - val_accuracy: 0.5969\n",
      "Epoch 104/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.8085e-04 - accuracy: 0.5781 - val_loss: 1.6396 - val_accuracy: 0.5594\n",
      "Epoch 105/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.5813 - val_loss: 1.6268 - val_accuracy: 0.5469\n",
      "Epoch 106/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 0.5594 - val_loss: 1.4532 - val_accuracy: 0.5719\n",
      "Epoch 107/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 0.5711 - val_loss: 1.5065 - val_accuracy: 0.5594\n",
      "Epoch 108/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.5789 - val_loss: 1.6733 - val_accuracy: 0.6375\n",
      "Epoch 109/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.6070 - val_loss: 1.6493 - val_accuracy: 0.5844\n",
      "Epoch 110/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 0.6047 - val_loss: 1.7140 - val_accuracy: 0.5750\n",
      "Epoch 111/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.5828 - val_loss: 1.6071 - val_accuracy: 0.6000\n",
      "Epoch 112/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.1361e-05 - accuracy: 0.5906 - val_loss: 1.5795 - val_accuracy: 0.5906\n",
      "Epoch 113/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.1022e-06 - accuracy: 0.5945 - val_loss: 1.6223 - val_accuracy: 0.5906\n",
      "Epoch 114/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.3545e-06 - accuracy: 0.5961 - val_loss: 1.6368 - val_accuracy: 0.5969\n",
      "Epoch 115/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.7133e-06 - accuracy: 0.5961 - val_loss: 1.6468 - val_accuracy: 0.6000\n",
      "Epoch 116/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.3420e-06 - accuracy: 0.5984 - val_loss: 1.6529 - val_accuracy: 0.6000\n",
      "Epoch 117/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.1133e-06 - accuracy: 0.6016 - val_loss: 1.6608 - val_accuracy: 0.6000\n",
      "Epoch 118/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.9066e-06 - accuracy: 0.6000 - val_loss: 1.6638 - val_accuracy: 0.6000\n",
      "Epoch 119/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.7691e-06 - accuracy: 0.6008 - val_loss: 1.6704 - val_accuracy: 0.6000\n",
      "Epoch 120/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.6548e-06 - accuracy: 0.6016 - val_loss: 1.6741 - val_accuracy: 0.6000\n",
      "Epoch 121/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.5504e-06 - accuracy: 0.6023 - val_loss: 1.6792 - val_accuracy: 0.6000\n",
      "Epoch 122/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.4623e-06 - accuracy: 0.6023 - val_loss: 1.6834 - val_accuracy: 0.6000\n",
      "Epoch 123/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.3936e-06 - accuracy: 0.6039 - val_loss: 1.6863 - val_accuracy: 0.6000\n",
      "Epoch 124/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.3273e-06 - accuracy: 0.6039 - val_loss: 1.6924 - val_accuracy: 0.5969\n",
      "Epoch 125/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.2673e-06 - accuracy: 0.6039 - val_loss: 1.6973 - val_accuracy: 0.5969\n",
      "Epoch 126/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.2172e-06 - accuracy: 0.6047 - val_loss: 1.6990 - val_accuracy: 0.6000\n",
      "Epoch 127/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.1686e-06 - accuracy: 0.6055 - val_loss: 1.7030 - val_accuracy: 0.6000\n",
      "Epoch 128/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.1251e-06 - accuracy: 0.6055 - val_loss: 1.7056 - val_accuracy: 0.6000\n",
      "Epoch 129/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.0857e-06 - accuracy: 0.6062 - val_loss: 1.7082 - val_accuracy: 0.6000\n",
      "Epoch 130/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.0515e-06 - accuracy: 0.6062 - val_loss: 1.7113 - val_accuracy: 0.6000\n",
      "Epoch 131/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.0203e-06 - accuracy: 0.6062 - val_loss: 1.7138 - val_accuracy: 0.6031\n",
      "Epoch 132/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 9.8601e-07 - accuracy: 0.6062 - val_loss: 1.7152 - val_accuracy: 0.6031\n",
      "Epoch 133/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 9.5871e-07 - accuracy: 0.6070 - val_loss: 1.7177 - val_accuracy: 0.6031\n",
      "Epoch 134/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 9.3351e-07 - accuracy: 0.6062 - val_loss: 1.7204 - val_accuracy: 0.6031\n",
      "Epoch 135/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 9.0861e-07 - accuracy: 0.6070 - val_loss: 1.7227 - val_accuracy: 0.6031\n",
      "Epoch 136/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 8.8460e-07 - accuracy: 0.6055 - val_loss: 1.7246 - val_accuracy: 0.6031\n",
      "Epoch 137/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 8.6536e-07 - accuracy: 0.6070 - val_loss: 1.7261 - val_accuracy: 0.6031\n",
      "Epoch 138/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 8.4499e-07 - accuracy: 0.6070 - val_loss: 1.7285 - val_accuracy: 0.6031\n",
      "Epoch 139/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 8.2416e-07 - accuracy: 0.6078 - val_loss: 1.7316 - val_accuracy: 0.6031\n",
      "Epoch 140/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 8.0578e-07 - accuracy: 0.6070 - val_loss: 1.7330 - val_accuracy: 0.6031\n",
      "Epoch 141/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.8877e-07 - accuracy: 0.6086 - val_loss: 1.7349 - val_accuracy: 0.6031\n",
      "Epoch 142/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.7142e-07 - accuracy: 0.6094 - val_loss: 1.7370 - val_accuracy: 0.6031\n",
      "Epoch 143/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.5720e-07 - accuracy: 0.6086 - val_loss: 1.7387 - val_accuracy: 0.6031\n",
      "Epoch 144/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.4222e-07 - accuracy: 0.6094 - val_loss: 1.7406 - val_accuracy: 0.6031\n",
      "Epoch 145/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.2747e-07 - accuracy: 0.6094 - val_loss: 1.7424 - val_accuracy: 0.6031\n",
      "Epoch 146/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.1419e-07 - accuracy: 0.6094 - val_loss: 1.7439 - val_accuracy: 0.6031\n",
      "Epoch 147/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 7.0027e-07 - accuracy: 0.6086 - val_loss: 1.7454 - val_accuracy: 0.6031\n",
      "Epoch 148/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.8797e-07 - accuracy: 0.6086 - val_loss: 1.7469 - val_accuracy: 0.6031\n",
      "Epoch 149/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.7660e-07 - accuracy: 0.6086 - val_loss: 1.7488 - val_accuracy: 0.6031\n",
      "Epoch 150/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.6534e-07 - accuracy: 0.6086 - val_loss: 1.7505 - val_accuracy: 0.6031\n",
      "Epoch 151/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.5427e-07 - accuracy: 0.6086 - val_loss: 1.7520 - val_accuracy: 0.6031\n",
      "Epoch 152/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.4332e-07 - accuracy: 0.6102 - val_loss: 1.7537 - val_accuracy: 0.6031\n",
      "Epoch 153/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.3366e-07 - accuracy: 0.6086 - val_loss: 1.7551 - val_accuracy: 0.6031\n",
      "Epoch 154/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.2335e-07 - accuracy: 0.6094 - val_loss: 1.7566 - val_accuracy: 0.6031\n",
      "Epoch 155/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.1434e-07 - accuracy: 0.6094 - val_loss: 1.7581 - val_accuracy: 0.6031\n",
      "Epoch 156/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 6.0497e-07 - accuracy: 0.6086 - val_loss: 1.7593 - val_accuracy: 0.6062\n",
      "Epoch 157/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.9680e-07 - accuracy: 0.6102 - val_loss: 1.7608 - val_accuracy: 0.6062\n",
      "Epoch 158/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.8762e-07 - accuracy: 0.6094 - val_loss: 1.7621 - val_accuracy: 0.6062\n",
      "Epoch 159/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.7970e-07 - accuracy: 0.6094 - val_loss: 1.7633 - val_accuracy: 0.6062\n",
      "Epoch 160/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.7126e-07 - accuracy: 0.6102 - val_loss: 1.7647 - val_accuracy: 0.6062\n",
      "Epoch 161/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.6352e-07 - accuracy: 0.6109 - val_loss: 1.7662 - val_accuracy: 0.6062\n",
      "Epoch 162/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.5583e-07 - accuracy: 0.6102 - val_loss: 1.7675 - val_accuracy: 0.6062\n",
      "Epoch 163/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.4902e-07 - accuracy: 0.6102 - val_loss: 1.7692 - val_accuracy: 0.6062\n",
      "Epoch 164/250\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.4152e-07 - accuracy: 0.6109 - val_loss: 1.7704 - val_accuracy: 0.6062\n",
      "Epoch 165/250\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 5.3511e-07 - accuracy: 0.6094 - val_loss: 1.7715 - val_accuracy: 0.6062\n",
      "Epoch 166/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.2834e-07 - accuracy: 0.6117 - val_loss: 1.7728 - val_accuracy: 0.6062\n",
      "Epoch 167/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.2183e-07 - accuracy: 0.6102 - val_loss: 1.7738 - val_accuracy: 0.6062\n",
      "Epoch 168/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.1576e-07 - accuracy: 0.6117 - val_loss: 1.7749 - val_accuracy: 0.6062\n",
      "Epoch 169/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.0950e-07 - accuracy: 0.6109 - val_loss: 1.7764 - val_accuracy: 0.6094\n",
      "Epoch 170/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 5.0372e-07 - accuracy: 0.6109 - val_loss: 1.7774 - val_accuracy: 0.6094\n",
      "Epoch 171/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.9786e-07 - accuracy: 0.6125 - val_loss: 1.7786 - val_accuracy: 0.6094\n",
      "Epoch 172/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.9227e-07 - accuracy: 0.6117 - val_loss: 1.7796 - val_accuracy: 0.6094\n",
      "Epoch 173/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.8704e-07 - accuracy: 0.6117 - val_loss: 1.7808 - val_accuracy: 0.6094\n",
      "Epoch 174/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.8127e-07 - accuracy: 0.6117 - val_loss: 1.7817 - val_accuracy: 0.6094\n",
      "Epoch 175/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.7676e-07 - accuracy: 0.6117 - val_loss: 1.7829 - val_accuracy: 0.6094\n",
      "Epoch 176/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.7202e-07 - accuracy: 0.6117 - val_loss: 1.7838 - val_accuracy: 0.6094\n",
      "Epoch 177/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.6684e-07 - accuracy: 0.6117 - val_loss: 1.7847 - val_accuracy: 0.6094\n",
      "Epoch 178/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.6197e-07 - accuracy: 0.6125 - val_loss: 1.7860 - val_accuracy: 0.6094\n",
      "Epoch 179/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.5744e-07 - accuracy: 0.6117 - val_loss: 1.7873 - val_accuracy: 0.6094\n",
      "Epoch 180/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.5251e-07 - accuracy: 0.6117 - val_loss: 1.7882 - val_accuracy: 0.6094\n",
      "Epoch 181/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.4867e-07 - accuracy: 0.6125 - val_loss: 1.7892 - val_accuracy: 0.6094\n",
      "Epoch 182/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.4372e-07 - accuracy: 0.6125 - val_loss: 1.7902 - val_accuracy: 0.6094\n",
      "Epoch 183/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.3942e-07 - accuracy: 0.6125 - val_loss: 1.7913 - val_accuracy: 0.6094\n",
      "Epoch 184/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.3558e-07 - accuracy: 0.6125 - val_loss: 1.7920 - val_accuracy: 0.6094\n",
      "Epoch 185/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.3137e-07 - accuracy: 0.6117 - val_loss: 1.7928 - val_accuracy: 0.6094\n",
      "Epoch 186/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.2702e-07 - accuracy: 0.6125 - val_loss: 1.7934 - val_accuracy: 0.6094\n",
      "Epoch 187/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.2340e-07 - accuracy: 0.6125 - val_loss: 1.7944 - val_accuracy: 0.6094\n",
      "Epoch 188/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.1972e-07 - accuracy: 0.6125 - val_loss: 1.7954 - val_accuracy: 0.6094\n",
      "Epoch 189/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.1590e-07 - accuracy: 0.6125 - val_loss: 1.7963 - val_accuracy: 0.6094\n",
      "Epoch 190/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.1250e-07 - accuracy: 0.6125 - val_loss: 1.7970 - val_accuracy: 0.6094\n",
      "Epoch 191/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.0863e-07 - accuracy: 0.6125 - val_loss: 1.7979 - val_accuracy: 0.6094\n",
      "Epoch 192/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.0548e-07 - accuracy: 0.6125 - val_loss: 1.7987 - val_accuracy: 0.6094\n",
      "Epoch 193/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.0177e-07 - accuracy: 0.6125 - val_loss: 1.7996 - val_accuracy: 0.6094\n",
      "Epoch 194/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.9825e-07 - accuracy: 0.6125 - val_loss: 1.8004 - val_accuracy: 0.6094\n",
      "Epoch 195/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.9479e-07 - accuracy: 0.6125 - val_loss: 1.8014 - val_accuracy: 0.6094\n",
      "Epoch 196/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.9145e-07 - accuracy: 0.6133 - val_loss: 1.8022 - val_accuracy: 0.6094\n",
      "Epoch 197/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.8826e-07 - accuracy: 0.6125 - val_loss: 1.8031 - val_accuracy: 0.6094\n",
      "Epoch 198/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.8521e-07 - accuracy: 0.6125 - val_loss: 1.8040 - val_accuracy: 0.6094\n",
      "Epoch 199/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.8225e-07 - accuracy: 0.6133 - val_loss: 1.8047 - val_accuracy: 0.6094\n",
      "Epoch 200/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.7918e-07 - accuracy: 0.6133 - val_loss: 1.8055 - val_accuracy: 0.6094\n",
      "Epoch 201/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.7602e-07 - accuracy: 0.6141 - val_loss: 1.8064 - val_accuracy: 0.6094\n",
      "Epoch 202/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.7342e-07 - accuracy: 0.6141 - val_loss: 1.8073 - val_accuracy: 0.6094\n",
      "Epoch 203/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.7013e-07 - accuracy: 0.6133 - val_loss: 1.8079 - val_accuracy: 0.6094\n",
      "Epoch 204/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.6711e-07 - accuracy: 0.6141 - val_loss: 1.8086 - val_accuracy: 0.6094\n",
      "Epoch 205/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.6427e-07 - accuracy: 0.6133 - val_loss: 1.8095 - val_accuracy: 0.6094\n",
      "Epoch 206/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.6170e-07 - accuracy: 0.6133 - val_loss: 1.8102 - val_accuracy: 0.6094\n",
      "Epoch 207/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.5882e-07 - accuracy: 0.6141 - val_loss: 1.8111 - val_accuracy: 0.6094\n",
      "Epoch 208/250\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 3.5628e-07 - accuracy: 0.6141 - val_loss: 1.8117 - val_accuracy: 0.6094\n",
      "Epoch 209/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.5376e-07 - accuracy: 0.6141 - val_loss: 1.8123 - val_accuracy: 0.6125\n",
      "Epoch 210/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.5094e-07 - accuracy: 0.6141 - val_loss: 1.8129 - val_accuracy: 0.6125\n",
      "Epoch 211/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.4843e-07 - accuracy: 0.6141 - val_loss: 1.8138 - val_accuracy: 0.6125\n",
      "Epoch 212/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.4596e-07 - accuracy: 0.6133 - val_loss: 1.8147 - val_accuracy: 0.6125\n",
      "Epoch 213/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.4335e-07 - accuracy: 0.6141 - val_loss: 1.8154 - val_accuracy: 0.6125\n",
      "Epoch 214/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.4105e-07 - accuracy: 0.6141 - val_loss: 1.8162 - val_accuracy: 0.6125\n",
      "Epoch 215/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.3850e-07 - accuracy: 0.6141 - val_loss: 1.8170 - val_accuracy: 0.6125\n",
      "Epoch 216/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.3630e-07 - accuracy: 0.6141 - val_loss: 1.8177 - val_accuracy: 0.6125\n",
      "Epoch 217/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.3414e-07 - accuracy: 0.6141 - val_loss: 1.8183 - val_accuracy: 0.6125\n",
      "Epoch 218/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.3151e-07 - accuracy: 0.6141 - val_loss: 1.8190 - val_accuracy: 0.6125\n",
      "Epoch 219/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.2939e-07 - accuracy: 0.6141 - val_loss: 1.8197 - val_accuracy: 0.6125\n",
      "Epoch 220/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.2713e-07 - accuracy: 0.6141 - val_loss: 1.8203 - val_accuracy: 0.6125\n",
      "Epoch 221/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.2498e-07 - accuracy: 0.6141 - val_loss: 1.8209 - val_accuracy: 0.6125\n",
      "Epoch 222/250\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.2289e-07 - accuracy: 0.6141 - val_loss: 1.8216 - val_accuracy: 0.6125\n",
      "Epoch 223/250\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 3.2051e-07 - accuracy: 0.6141 - val_loss: 1.8224 - val_accuracy: 0.6125\n",
      "Epoch 224/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.1851e-07 - accuracy: 0.6141 - val_loss: 1.8230 - val_accuracy: 0.6125\n",
      "Epoch 225/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.1647e-07 - accuracy: 0.6141 - val_loss: 1.8237 - val_accuracy: 0.6125\n",
      "Epoch 226/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.1444e-07 - accuracy: 0.6141 - val_loss: 1.8245 - val_accuracy: 0.6125\n",
      "Epoch 227/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.1251e-07 - accuracy: 0.6141 - val_loss: 1.8251 - val_accuracy: 0.6125\n",
      "Epoch 228/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.1068e-07 - accuracy: 0.6141 - val_loss: 1.8258 - val_accuracy: 0.6125\n",
      "Epoch 229/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.0849e-07 - accuracy: 0.6133 - val_loss: 1.8262 - val_accuracy: 0.6125\n",
      "Epoch 230/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.0657e-07 - accuracy: 0.6148 - val_loss: 1.8269 - val_accuracy: 0.6125\n",
      "Epoch 231/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.0472e-07 - accuracy: 0.6133 - val_loss: 1.8275 - val_accuracy: 0.6125\n",
      "Epoch 232/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.0297e-07 - accuracy: 0.6133 - val_loss: 1.8281 - val_accuracy: 0.6125\n",
      "Epoch 233/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 3.0101e-07 - accuracy: 0.6148 - val_loss: 1.8288 - val_accuracy: 0.6125\n",
      "Epoch 234/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.9924e-07 - accuracy: 0.6133 - val_loss: 1.8293 - val_accuracy: 0.6125\n",
      "Epoch 235/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.9741e-07 - accuracy: 0.6133 - val_loss: 1.8299 - val_accuracy: 0.6125\n",
      "Epoch 236/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.9551e-07 - accuracy: 0.6133 - val_loss: 1.8304 - val_accuracy: 0.6125\n",
      "Epoch 237/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.9400e-07 - accuracy: 0.6141 - val_loss: 1.8310 - val_accuracy: 0.6125\n",
      "Epoch 238/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.9224e-07 - accuracy: 0.6133 - val_loss: 1.8316 - val_accuracy: 0.6125\n",
      "Epoch 239/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.9039e-07 - accuracy: 0.6133 - val_loss: 1.8322 - val_accuracy: 0.6125\n",
      "Epoch 240/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.8871e-07 - accuracy: 0.6141 - val_loss: 1.8327 - val_accuracy: 0.6125\n",
      "Epoch 241/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.8714e-07 - accuracy: 0.6141 - val_loss: 1.8333 - val_accuracy: 0.6125\n",
      "Epoch 242/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.8543e-07 - accuracy: 0.6141 - val_loss: 1.8339 - val_accuracy: 0.6125\n",
      "Epoch 243/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.8376e-07 - accuracy: 0.6133 - val_loss: 1.8343 - val_accuracy: 0.6125\n",
      "Epoch 244/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.8216e-07 - accuracy: 0.6141 - val_loss: 1.8350 - val_accuracy: 0.6125\n",
      "Epoch 245/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.8061e-07 - accuracy: 0.6141 - val_loss: 1.8355 - val_accuracy: 0.6125\n",
      "Epoch 246/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.7906e-07 - accuracy: 0.6133 - val_loss: 1.8360 - val_accuracy: 0.6125\n",
      "Epoch 247/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.7755e-07 - accuracy: 0.6141 - val_loss: 1.8366 - val_accuracy: 0.6125\n",
      "Epoch 248/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.7609e-07 - accuracy: 0.6133 - val_loss: 1.8371 - val_accuracy: 0.6125\n",
      "Epoch 249/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.7444e-07 - accuracy: 0.6141 - val_loss: 1.8376 - val_accuracy: 0.6125\n",
      "Epoch 250/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 2.7285e-07 - accuracy: 0.6141 - val_loss: 1.8382 - val_accuracy: 0.6125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7e44d61b50>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=250,validation_split=0.2,batch_size=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
